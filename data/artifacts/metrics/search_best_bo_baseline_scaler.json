{
  "cfg": {
    "input_chunk_length": 24,
    "output_chunk_length": 6,
    "hidden_size": 64,
    "num_attention_heads": 4,
    "lstm_layers": 2,
    "hidden_continuous_size": 24,
    "dropout": 0.05,
    "batch_size": 128,
    "n_epochs": 50,
    "lr": 0.0008200093911665294,
    "weight_decay": 0.0006486894882959159
  },
  "metrics": {
    "mql_0_50": 26.34598604965988,
    "rmse": 30.028506121917193,
    "mae": 26.34598604965988,
    "smape": 62.0247514707618,
    "mic_10_90": 0.6826741996233523
  }
}